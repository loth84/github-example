{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://towardsdatascience.com/an-introduction-to-web-scraping-with-python-a2601e8619e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "###### Import necessary dependancy#######\n",
    "#############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "###############################################################\n",
    "###### Import necessary dependancy#######\n",
    "#############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "###############################################################\n",
    "###### Import necessary  library for  scraping more page#######\n",
    "############################################################\n",
    "from bs4 import BeautifulSoup # Import Beautifulsoup to scraping the web pafr\n",
    "from requests import get # import get from request to get all the pa\n",
    "main_url = \"http://books.toscrape.com/index.html\"\n",
    "import requests\n",
    "result = requests.get(main_url)\n",
    "result.text[:1000]\n",
    "###############################################################\n",
    "###### Import necessary  library for  scraping more page#######\n",
    "#############################################################\n",
    "\n",
    "from bs4 import BeautifulSoup # Import Beautifulsoup to scraping the web pafr\n",
    "from requests import get # import get from request to get all the pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up: get the content of the main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"http://books.toscrape.com/index.html\"\n",
    "\n",
    "import requests\n",
    "result = requests.get(main_url)\n",
    "#result.text[:1000]\n",
    "\n",
    "soup = BeautifulSoup(result.text, 'html.parser')\n",
    "#print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let’s define a function to request and parse a HTML web page as we will need this a lot during this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAndParseURL(url):\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "    return(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup enables us to find those special ‘article’ tags. We can wall the  \n",
    "find() function in order to find the first occurence of this tag in the HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<article class=\"product_pod\">\n",
       "<div class=\"image_container\">\n",
       "<a href=\"catalogue/a-light-in-the-attic_1000/index.html\"><img alt=\"A Light in the Attic\" class=\"thumbnail\" src=\"media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg\"/></a>\n",
       "</div>\n",
       "<p class=\"star-rating Three\">\n",
       "<i class=\"icon-star\"></i>\n",
       "<i class=\"icon-star\"></i>\n",
       "<i class=\"icon-star\"></i>\n",
       "<i class=\"icon-star\"></i>\n",
       "<i class=\"icon-star\"></i>\n",
       "</p>\n",
       "<h3><a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>\n",
       "<div class=\"product_price\">\n",
       "<p class=\"price_color\">Â£51.77</p>\n",
       "<p class=\"instock availability\">\n",
       "<i class=\"icon-ok\"></i>\n",
       "    \n",
       "        In stock\n",
       "    \n",
       "</p>\n",
       "<form>\n",
       "<button class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\" type=\"submit\">Add to basket</button>\n",
       "</form>\n",
       "</div>\n",
       "</article>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"article\", class_ = \"product_pod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let’s dive deeper in the tree by adding the other child tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"catalogue/a-light-in-the-attic_1000/index.html\"><img alt=\"A Light in the Attic\" class=\"thumbnail\" src=\"media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg\"/></a>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"article\", class_ = \"product_pod\").div.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can get this by adding .get(“href”) to the previous instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catalogue/a-light-in-the-attic_1000/index.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"article\", class_ = \"product_pod\").div.a.get('href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let’s gather all the products URLs on the main web page at once using the findAll() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 fetched products URLs\n",
      "One example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'catalogue/a-light-in-the-attic_1000/index.html'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_page_products_urls = [x.div.a.get('href') for x in soup.findAll(\"article\", class_ = \"product_pod\")]\n",
    "\n",
    "print(str(len(main_page_products_urls)) + \" fetched products URLs\")\n",
    "print(\"One example:\")\n",
    "main_page_products_urls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let’s use this to define a function to retrieve book links on any given page of the website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBooksURLs(url):\n",
    "    soup = getAndParseURL(url)\n",
    "    # remove the index.html part of the base url before returning the results\n",
    "    return([\"/\".join(url.split(\"/\")[:-1]) + \"/\" + x.div.a.get('href') for x in soup.findAll(\"article\", class_ = \"product_pod\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can tell BeautifulSoup to match the URLs that contain this pattern in order to retrieve easily the categories URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 fetched categories URLs\n",
      "Some examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/index.htmlcatalogue/category/books/travel_2/index.html',\n",
       " 'http://books.toscrape.com/index.htmlcatalogue/category/books/mystery_3/index.html',\n",
       " 'http://books.toscrape.com/index.htmlcatalogue/category/books/historical-fiction_4/index.html',\n",
       " 'http://books.toscrape.com/index.htmlcatalogue/category/books/sequential-art_5/index.html',\n",
       " 'http://books.toscrape.com/index.htmlcatalogue/category/books/classics_6/index.html']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "categories_urls = [main_url + x.get('href') for x in soup.find_all(\"a\", href=re.compile(\"catalogue/category/books\"))]\n",
    "categories_urls = categories_urls[1:] # we remove the first one because it corresponds to all the books\n",
    "\n",
    "print(str(len(categories_urls)) + \" fetched categories URLs\")\n",
    "print(\"Some examples:\")\n",
    "categories_urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to fetch all the products URLs, we need to be able to get through all the pages.  To do so, we can go iteratively through all the ‘next’ buttons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 fetched URLs\n",
      "Some examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/index.html',\n",
       " 'http://books.toscrape.com/catalogue/page-2.html',\n",
       " 'http://books.toscrape.com/catalogue/page-3.html',\n",
       " 'http://books.toscrape.com/catalogue/page-4.html',\n",
       " 'http://books.toscrape.com/catalogue/page-5.html']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store all the results into a list\n",
    "pages_urls = [main_url]\n",
    "\n",
    "soup = getAndParseURL(pages_urls[0])\n",
    "\n",
    "# while we get two matches, this means that the webpage contains a 'previous' and a 'next' button\n",
    "# if there is only one button, this means that we are either on the first page or on the last page\n",
    "# we stop when we get to the last page\n",
    "\n",
    "while len(soup.findAll(\"a\", href=re.compile(\"page\"))) == 2 or len(pages_urls) == 1:\n",
    "    \n",
    "    # get the new complete url by adding the fetched URL to the base URL (and removing the .html part of the base URL)\n",
    "    new_url = \"/\".join(pages_urls[-1].split(\"/\")[:-1]) + \"/\" + soup.findAll(\"a\", href=re.compile(\"page\"))[-1].get(\"href\")\n",
    "    \n",
    "    # add the URL to the list\n",
    "    pages_urls.append(new_url)\n",
    "    \n",
    "    # parse the next page\n",
    "    soup = getAndParseURL(new_url)\n",
    "    \n",
    "\n",
    "print(str(len(pages_urls)) + \" fetched URLs\")\n",
    "print(\"Some examples:\")\n",
    "pages_urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fortunately the result of a request has a very useful attribute that can show us the return status of the HTML request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code for page 50: 200\n",
      "status code for page 51: 404\n"
     ]
    }
   ],
   "source": [
    "result = requests.get(\"http://books.toscrape.com/catalogue/page-50.html\")\n",
    "print(\"status code for page 50: \" + str(result.status_code))\n",
    "\n",
    "result = requests.get(\"http://books.toscrape.com/catalogue/page-51.html\")\n",
    "print(\"status code for page 51: \" + str(result.status_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use this information to get all our pages URLs: we should iterate until we get a 404 code.\n",
    "\n",
    "### Let’s try this method now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 fetched URLs\n",
      "Some examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/catalogue/page-1.html',\n",
       " 'http://books.toscrape.com/catalogue/page-2.html',\n",
       " 'http://books.toscrape.com/catalogue/page-3.html',\n",
       " 'http://books.toscrape.com/catalogue/page-4.html',\n",
       " 'http://books.toscrape.com/catalogue/page-5.html']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_urls = []\n",
    "\n",
    "new_page = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "while requests.get(new_page).status_code == 200:\n",
    "    pages_urls.append(new_page)\n",
    "    new_page = pages_urls[-1].split(\"-\")[0] + \"-\" + str(int(pages_urls[-1].split(\"-\")[1].split(\".\")[0]) + 1) + \".html\"\n",
    "    \n",
    "\n",
    "print(str(len(pages_urls)) + \" fetched URLs\")\n",
    "print(\"Some examples:\")\n",
    "pages_urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all products URLs\n",
    "Now the next step consists in fetching all the products URLs for every page    \n",
    "This step is quite simple as we already have the list of all pages and the function  \n",
    "to get products URLs from a page.\n",
    "\n",
    "Let’s iterate through the pages and apply our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 fetched URLs\n",
      "Some examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html',\n",
       " 'http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html',\n",
       " 'http://books.toscrape.com/catalogue/soumission_998/index.html',\n",
       " 'http://books.toscrape.com/catalogue/sharp-objects_997/index.html',\n",
       " 'http://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booksURLs = []\n",
    "for page in pages_urls:\n",
    "    booksURLs.extend(getBooksURLs(page))\n",
    "    \n",
    "print(str(len(booksURLs)) + \" fetched URLs\")\n",
    "print(\"Some examples:\")\n",
    "booksURLs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get product data\n",
    "The last step consist in scraping the data for each product.  \n",
    "Let’s explore first how the information is structured on the products pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nb_in_stock</th>\n",
       "      <th>price</th>\n",
       "      <th>product_category</th>\n",
       "      <th>rating</th>\n",
       "      <th>url_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>22</td>\n",
       "      <td>51.77</td>\n",
       "      <td>poetry_23</td>\n",
       "      <td>Three</td>\n",
       "      <td>http://books.toscrape.com/catalogue/a-light-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>20</td>\n",
       "      <td>53.74</td>\n",
       "      <td>historical-fiction_4</td>\n",
       "      <td>One</td>\n",
       "      <td>http://books.toscrape.com/catalogue/tipping-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>20</td>\n",
       "      <td>50.10</td>\n",
       "      <td>fiction_10</td>\n",
       "      <td>One</td>\n",
       "      <td>http://books.toscrape.com/catalogue/soumission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>20</td>\n",
       "      <td>47.82</td>\n",
       "      <td>mystery_3</td>\n",
       "      <td>Four</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sharp-obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>20</td>\n",
       "      <td>54.23</td>\n",
       "      <td>history_32</td>\n",
       "      <td>Five</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sapiens-a-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name nb_in_stock  price  \\\n",
       "0                   A Light in the Attic          22  51.77   \n",
       "1                     Tipping the Velvet          20  53.74   \n",
       "2                             Soumission          20  50.10   \n",
       "3                          Sharp Objects          20  47.82   \n",
       "4  Sapiens: A Brief History of Humankind          20  54.23   \n",
       "\n",
       "       product_category rating  \\\n",
       "0             poetry_23  Three   \n",
       "1  historical-fiction_4    One   \n",
       "2            fiction_10    One   \n",
       "3             mystery_3   Four   \n",
       "4            history_32   Five   \n",
       "\n",
       "                                             url_img  \n",
       "0  http://books.toscrape.com/catalogue/a-light-in...  \n",
       "1  http://books.toscrape.com/catalogue/tipping-th...  \n",
       "2  http://books.toscrape.com/catalogue/soumission...  \n",
       "3  http://books.toscrape.com/catalogue/sharp-obje...  \n",
       "4  http://books.toscrape.com/catalogue/sapiens-a-...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booksURLs = []\n",
    "for page in pages_urls:\n",
    "    booksURLs.extend(getBooksURLs(page))\n",
    "    \n",
    "print(str(len(booksURLs)) + \" fetched URLs\")\n",
    "print(\"Some examples:\")\n",
    "booksURLs[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
